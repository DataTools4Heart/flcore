################################################################################

# Flcore configuration file

################################################################################


################################################################################
# Experiment parameters
################################################################################

##############  Dataset type to use
# Possible values: , kaggle_hf, diabetes, mnist, dt4h_format
dataset: kaggle_hf
# dataset: ukbb_cvd
# dataset: diabetes
#custom
#libsvm
#kaggle_hf

# ****** * * * * * * *  *  *   *    *    *  *  * * * * * * * *******************
# New variables
# ****** * * * * * * *  *  *   *    *    *  *  * * * * * * * *******************
metadata_file: metadata.json
data_file : 3362-2045-1944.parquet
# Options: IQR STD MIN_MAX
normalization_method : IQR

train_labels: ["encounters_encounterClass","encounters_admissionYear","vital_signs_systolicBp_value_last",
               "patient_demographics_gender","patient_demographics_age","vital_signs_weight_value_last",
               "vital_signs_height_value_first","lab_results_crpNonHs_value_avg","lab_results_tropIHs_value_min"]
target_label: ["conditions_stroke_any"] #,"conditions_vd_any"]

train_size: 0.7
# ****** * * * * * * *  *  *   *    *    *  *  * * * * * * * *******************

##############  Number of clients (data centers) to use for training
num_clients: 4

############## Model type
# Possible values: logistic_regression, lsvc, elastic_net, random_forest, weighted_random_forest, xgb
# See README.md for a full list of supported models
# model: xgb
model: logistic_regression
# model: random_forest
#logistic_regression
#random_forest

############## Training length
num_rounds: 10

############## Metric to select the best model
# Possible values: accuracy, balanced_accuracy, f1, precision, recall
# checkpoint_selection_metric:  precision
checkpoint_selection_metric:  balanced_accuracy
#balanced_accuracy

############## Experiment logging
experiment:
  name: experiment_kaggle_standard
  log_path: logs
  debug: true


################################################################################
# Federated Data Preprocessing
################################################################################

# Strategy to calculate data preprocessing parameters between clients. 
# It covers missing data imputation, label encoding, normalization and feature selection
# It can be one of: 
  # "reference" - use reference center to calculate all parameters (largest or random)
  # "equal_aggregate" - aggregate parameters from all clients based on mean and voting disregarding center size
  # "weighted_aggregate" - aggregate parameters from all clients based on weighted mean and voting

# data_preprocessing_method: "equal_aggregate"
data_preprocessing_method: "reference"

# Toggle data normalization (Standard scaler) based on largest center (global) or local client
data_normalization: "local"

# Determine target for feature selection number
n_features: Null


################################################################################
# Aggregation methods
################################################################################

############## Centre-dropout
# Possible values: None, random_dropout, Fast_at_odd_rounds, LessParticipants
dropout_method: None
dropout:
  percentage_drop: 50

############## Weight smoothing
# Possible values: None, SlowerQuartile, EqualVoting
smooth_method: None
smoothWeights:
  smoothing_strenght: 0.5

################################################################################
# Model specific parameters
################################################################################

# Number of features to select for model input

# info: If None, all features are used
# higher value of features may increase performance at the risk of overfitting
# Kaggle dataset has 9 features
# UKBB dataset has 40 features

linear_models:
  n_features: 9


dirichlet_alpha: Null

# Random Forest
random_forest:
  balanced_rf: true
  tree_num: 300

# Weighted Random Forest
weighted_random_forest:
  balanced_rf: true
  levelOfDetail: DecisionTree

# XGBoost
xgb:
  batch_size: 32
  num_iterations: 100
  task_type: BINARY
  tree_num: 300


held_out_center_id: -1

################################################################################
# Library configuration

seed: 42

local_port: 8081

data_path: dataset/

production_mode: False # Turn on to use environment variables such as data path, server address, certificates etc.
